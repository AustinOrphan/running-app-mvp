name: ğŸš€ Performance Monitoring

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # Run weekly performance audits
    - cron: '0 9 * * MON'

permissions:
  contents: read
  issues: write
  pull-requests: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  lighthouse-ci:
    name: ğŸ” Lighthouse CI
    runs-on: ubuntu-latest
    timeout-minutes: 20
    env:
      DATABASE_URL: file:./prisma/test.db
      JWT_SECRET: test-secret-key

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version-file: '.nvmrc'
          cache: 'npm'

      - name: ğŸ“¥ Install dependencies
        run: npm ci

      - name: ğŸ—„ï¸ Setup database
        run: |
          npx prisma migrate dev --name init || npx prisma migrate deploy
          npx prisma generate
          # Ensure database file exists
          touch dev.db

      - name: ğŸ—ï¸ Build frontend only
        run: npm run build

      - name: ğŸŒ Start backend server
        run: |
          echo "Starting backend server on port 3001..."
          npm run dev > backend.log 2>&1 &
          echo "Backend PID: $!"
          echo "Waiting for backend server to start..."
          npx wait-on http://localhost:3001/api/health --timeout 30000 || (echo "Backend logs:" && cat backend.log && exit 1)
          echo "Backend server is ready!"
        env:
          NODE_ENV: production
          DATABASE_URL: file:./dev.db
          JWT_SECRET: test-secret-for-ci
          PORT: 3001

      - name: ğŸŒ Start frontend server
        run: |
          echo "Starting frontend server on port 3000..."
          npm run preview -- --port 3000 --host > frontend.log 2>&1 &
          echo "Frontend PID: $!"
          echo "Waiting for frontend server to start..."
          npx wait-on http://localhost:3000 --timeout 30000 || (echo "Frontend logs:" && cat frontend.log && exit 1)
          echo "Frontend server is ready!"
        env:
          NODE_ENV: production

      - name: ğŸ” Run Lighthouse CI
        uses: treosh/lighthouse-ci-action@v12
        with:
          configPath: '.lighthouserc.json'
          uploadArtifacts: true
          temporaryPublicStorage: true
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN || github.token }}

  bundle-analysis:
    name: ğŸ“¦ Bundle Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 15
    env:
      DATABASE_URL: file:./prisma/test.db
      JWT_SECRET: test-secret-key

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version-file: '.nvmrc'
          cache: 'npm'

      - name: ğŸ“¥ Install dependencies
        run: npm ci

      - name: ğŸ—„ï¸ Setup database
        run: |
          npx prisma migrate deploy
          npx prisma generate

      - name: ğŸ—ï¸ Build and analyze bundle
        run: |
          npm run build
          echo '{"size": "Bundle analysis not implemented yet"}' > bundle-report.json

      - name: ğŸ“Š Upload bundle analysis
        uses: actions/upload-artifact@v4
        with:
          name: bundle-analysis
          path: bundle-report.json
          retention-days: 30

  performance-benchmarks:
    name: âš¡ Performance Benchmarks
    runs-on: ubuntu-latest
    timeout-minutes: 25
    env:
      DATABASE_URL: file:./prisma/test.db
      JWT_SECRET: test-secret-key

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version-file: '.nvmrc'
          cache: 'npm'

      - name: ğŸ“¥ Install dependencies
        run: npm ci

      - name: ğŸ—„ï¸ Setup database
        run: |
          npx prisma migrate deploy
          npx prisma generate

      - name: âš¡ Run performance benchmarks
        id: benchmarks
        run: |
          mkdir -p benchmark-results
          npm run test:performance:ci || echo "BENCHMARK_FAILED=true" >> $GITHUB_ENV
        continue-on-error: true

      - name: ğŸ“Š Generate performance report
        if: always()
        run: |
          npm run test:performance:report || true

      - name: ğŸ“ˆ Upload benchmark results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-benchmarks
          path: |
            benchmark-results/
            performance-results.json
            performance-report.md
            performance-report.html
          retention-days: 30

      - name: ğŸ’¬ Comment performance results on PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            if (fs.existsSync('benchmark-results/performance-report.md')) {
              const report = fs.readFileSync('benchmark-results/performance-report.md', 'utf8');
              
              // Find and update existing comment or create new one
              const { data: comments } = await github.rest.issues.listComments({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
              });
              
              const botComment = comments.find(comment => 
                comment.user.type === 'Bot' && 
                comment.body.includes('ğŸš€ Performance Report')
              );
              
              const commentBody = `${report}\n\n---\n<sub>Generated by Performance CI</sub>`;
              
              if (botComment) {
                await github.rest.issues.updateComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  comment_id: botComment.id,
                  body: commentBody
                });
              } else {
                await github.rest.issues.createComment({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  issue_number: context.issue.number,
                  body: commentBody
                });
              }
            }

  memory-leak-detection:
    name: ğŸ§  Memory Leak Detection
    runs-on: ubuntu-latest
    timeout-minutes: 20
    env:
      DATABASE_URL: file:./prisma/test.db
      JWT_SECRET: test-secret-key

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version-file: '.nvmrc'
          cache: 'npm'

      - name: ğŸ“¥ Install dependencies
        run: npm ci

      - name: ğŸ—„ï¸ Setup database
        run: |
          npx prisma migrate deploy
          npx prisma generate

      - name: ğŸ§  Run memory leak tests
        run: npm run test:memory
        continue-on-error: true

      - name: ğŸ“Š Upload memory analysis
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: memory-analysis
          path: memory-reports/
          retention-days: 30

  performance-report:
    name: ğŸ“Š Performance Report
    runs-on: ubuntu-latest
    needs: [lighthouse-ci, bundle-analysis, performance-benchmarks, memory-leak-detection]
    if: always()
    timeout-minutes: 10

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ğŸ“¥ Download all artifacts
        uses: actions/download-artifact@v4

      - name: ğŸ“Š Generate performance report
        run: |
          echo "# ğŸš€ Performance Report" > performance-report.md
          echo "" >> performance-report.md
          echo "## ğŸ“Š Summary" >> performance-report.md
          echo "- **Lighthouse CI**: $([ -f lighthouse-ci/results.json ] && echo 'âœ… Completed' || echo 'âŒ Failed')" >> performance-report.md
          echo "- **Bundle Analysis**: $([ -f bundle-analysis/bundle-report.json ] && echo 'âœ… Completed' || echo 'âŒ Failed')" >> performance-report.md
          echo "- **Performance Benchmarks**: $([ -d performance-benchmarks ] && echo 'âœ… Completed' || echo 'âŒ Failed')" >> performance-report.md
          echo "- **Memory Leak Detection**: $([ -d memory-analysis ] && echo 'âœ… Completed' || echo 'âŒ Failed')" >> performance-report.md
          echo "" >> performance-report.md
          echo "Generated on: $(date)" >> performance-report.md

      - name: ğŸ“ Comment performance report on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            if (fs.existsSync('performance-report.md')) {
              const report = fs.readFileSync('performance-report.md', 'utf8');
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: report
              });
            }

      - name: ğŸ“Š Upload performance report
        uses: actions/upload-artifact@v4
        with:
          name: performance-report
          path: performance-report.md
          retention-days: 30
